{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwGHe3T5-Fhm"
   },
   "source": [
    "**First, generate statistics on a multi-tab Excel workbook representing multiple sheets of survey data representing the ALS TDI CDC cohort.**\n",
    "\n",
    "**What this does**\n",
    "\n",
    "Loop through all fields and result in an Excel notebook with a tab for each tab represented in the data set.\n",
    "\n",
    "Create a new dataframe based on the data dictionary.\n",
    "\n",
    "If there is more than one row per Subject (Subject = unique identifier), first restructure from long to wide so that there is one row per subject.\n",
    "\n",
    "Then create a separate descriptive analysis for each tab in the Excel file representing descriptive and categorical analytics for evry field in every survey.  \n",
    "\n",
    "Save results in separate tabs as a \"chartbook.\"\n",
    "\n",
    "Repeat for Looker formatted files, which have a different format from the format of the original CDC cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TmqJNceNR69t",
    "outputId": "fd632f06-d2ca-43c4-c830-3d9b49bb0ac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive analysis has been saved to the Excel workbook.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "survey_data_path = 'XXXSURVEYDATAINPUT.xlsx'\n",
    "output_path = 'XXXSURVEYDATAOUTPUT.xlsx'\n",
    "\n",
    "# Load the survey data\n",
    "survey_sheets = pd.read_excel(survey_data_path, sheet_name=None)\n",
    "\n",
    "# Function to restructure from long to wide format\n",
    "def restructure_long_to_wide(df):\n",
    "    if 'Subject' in df.columns:\n",
    "        # Pivot the data to wide format using 'Subject' as the index\n",
    "        wide_df = df.pivot_table(index='Subject', aggfunc='first').reset_index()\n",
    "        return wide_df\n",
    "    return df\n",
    "\n",
    "# Function to create descriptive analysis for categorical variables\n",
    "def create_categorical_analysis(df):\n",
    "    results = []\n",
    "    for column in df.select_dtypes(include=['object', 'category']):\n",
    "        counts = df[column].value_counts(dropna=False)\n",
    "        percentages = (counts / len(df) * 100).round(2)\n",
    "        total = counts.sum()\n",
    "        analysis = pd.DataFrame({\n",
    "            'Value': counts.index,\n",
    "            'Count': counts.values,\n",
    "            'Percentage': percentages.values,\n",
    "            'Total': total\n",
    "        })\n",
    "        analysis['Variable'] = column\n",
    "        results.append(analysis)\n",
    "    if results:\n",
    "        return pd.concat(results, ignore_index=True)\n",
    "    return None\n",
    "\n",
    "# Function to create descriptive analysis for numeric variables\n",
    "def create_numeric_analysis(df):\n",
    "    if not df.empty:\n",
    "        description = df.describe(include='all').transpose()\n",
    "        description['count'] = description['count'].astype(int)\n",
    "        description['%'] = (description['count'] / len(df) * 100).round(2)\n",
    "        return description\n",
    "    return None\n",
    "\n",
    "# Function to clean sheet names to meet Excel's constraints\n",
    "def clean_sheet_name(name):\n",
    "    # Remove invalid characters\n",
    "    invalid_chars = ['\\\\', '/', '*', '[', ']', ':', '?']\n",
    "    for char in invalid_chars:\n",
    "        name = name.replace(char, '')\n",
    "    # Truncate to 31 characters\n",
    "    return name[:31]\n",
    "\n",
    "# Initialize an Excel writer\n",
    "with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "    for sheet_name, df in survey_sheets.items():\n",
    "        # Restructure from long to wide format\n",
    "        wide_df = restructure_long_to_wide(df)\n",
    "\n",
    "        # Perform numeric descriptive analysis\n",
    "        numeric_description = create_numeric_analysis(wide_df)\n",
    "\n",
    "        # Write the numeric descriptive analysis to Excel\n",
    "        if numeric_description is not None:\n",
    "            clean_name = clean_sheet_name(f'{sheet_name}_Numeric_Description')\n",
    "            numeric_description.to_excel(writer, sheet_name=clean_name)\n",
    "\n",
    "        # Perform categorical analysis\n",
    "        categorical_analysis = create_categorical_analysis(wide_df)\n",
    "\n",
    "        # Write the combined categorical analysis to Excel\n",
    "        if categorical_analysis is not None:\n",
    "            clean_name = clean_sheet_name(f'{sheet_name}_Categorical_Description')\n",
    "            categorical_analysis.to_excel(writer, sheet_name=clean_name, index=False)\n",
    "\n",
    "    # Ensure at least one sheet is visible\n",
    "    if 'Sheet' in writer.book.sheetnames:\n",
    "        std = writer.book['Sheet']\n",
    "        writer.book.remove(std)\n",
    "    if not writer.book.sheetnames:\n",
    "        writer.book.create_sheet(title='Summary')\n",
    "\n",
    "# Indicate that processing is complete\n",
    "print(\"Descriptive analysis has been saved to the Excel workbook.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuruyUerl-p2"
   },
   "source": [
    "**Read in updated data exported from Looker.**\n",
    "First we convert the text file to CSV, although we could have done it straight from txt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4BJRvEsVkd3b"
   },
   "outputs": [],
   "source": [
    "#This pivots all but conditions and family history. \n",
    "import pandas as pd\n",
    "\n",
    "# Paths to your files\n",
    "csv_file_path = 'XXXLOOKERDATAINPUT.csv'\n",
    "output_file_path = 'XXXLOOKERDATAOUTPUT.xlsx'\n",
    "\n",
    "# Load the CSV file\n",
    "dblooker_data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Create a new Excel writer object\n",
    "with pd.ExcelWriter(output_file_path, engine='xlsxwriter') as writer:\n",
    "    for survey_title in dblooker_data['Survey Data Survey Title'].unique():\n",
    "        # Filter data for the current survey title\n",
    "        survey_data = dblooker_data[dblooker_data['Survey Data Survey Title'] == survey_title]\n",
    "\n",
    "        # Pivot the data to align with the structure of the Excel sheets\n",
    "        pivot_table = survey_data.pivot_table(\n",
    "            index='Survey Data Participant ID',\n",
    "            columns='Survey Data Question Title',\n",
    "            values='Survey Data Answer Value',\n",
    "            aggfunc='first'\n",
    "        )\n",
    "\n",
    "        # Write the pivot table to a sheet named after the survey title\n",
    "        pivot_table.to_excel(writer, sheet_name=survey_title[:31])  # Excel sheet names are limited to 31 characters\n",
    "\n",
    "print(f\"Restructured data saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKZvYYqaEOs7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to your files\n",
    "csv_file_path = 'XXXCONDITIONSINPUT.csv'\n",
    "conditions_output_path = 'XXXCONDITIONSOUTPUT.xlsx'\n",
    "\n",
    "# Load the CSV file\n",
    "dblooker_data_updated = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Specify the condition titles we identified\n",
    "condition_titles = ['Conditions 1', 'Conditions 2', 'Conditions 3', 'Conditions 4']\n",
    "\n",
    "# Function to split conditions into separate columns\n",
    "def separate_conditions(data, condition_column):\n",
    "    # Split the conditions using the separator and expand into separate columns\n",
    "    conditions_expanded = data[condition_column].str.split(' \\| ', expand=True)\n",
    "\n",
    "    # Reshape the data into a long format and remove NaN values\n",
    "    conditions_melted = conditions_expanded.melt(value_name='Condition').dropna()\n",
    "\n",
    "    # Get unique conditions\n",
    "    unique_conditions = conditions_melted['Condition'].unique()\n",
    "\n",
    "    # Create a new DataFrame with columns for each unique condition\n",
    "    for condition in unique_conditions:\n",
    "        if condition.startswith(\"Other - Write In\"):\n",
    "            # Extract and store the specific \"Other\" write-in response\n",
    "            data[condition] = data[condition_column].apply(\n",
    "                lambda x: x if condition in x else None)\n",
    "        else:\n",
    "            # Assign a boolean column indicating whether the condition was present\n",
    "            data[condition] = data[condition_column].str.contains(condition, na=False)\n",
    "\n",
    "    return data.drop(columns=[condition_column])\n",
    "\n",
    "# Create a new Excel writer object\n",
    "with pd.ExcelWriter(conditions_output_path, engine='xlsxwriter') as writer:\n",
    "    for title in condition_titles:\n",
    "        # Filter data for the current survey title\n",
    "        survey_data = dblooker_data_updated[dblooker_data_updated['Survey Data Survey Title'] == title]\n",
    "\n",
    "        if survey_data.empty:\n",
    "            print(f\"No data found matching the title '{title}'.\")\n",
    "            continue\n",
    "\n",
    "        # Debugging: Check the first few entries to ensure data capture\n",
    "        print(f\"Data for {title}:\")\n",
    "        print(survey_data.head())\n",
    "\n",
    "        # Restructure the data to focus on question titles\n",
    "        try:\n",
    "            # Create a DataFrame with Subject and Submitted columns\n",
    "            subject_data = survey_data[['Survey Data Participant ID', 'Survey Data Date Submitted Date']].drop_duplicates()\n",
    "            subject_data.columns = ['Subject', 'Submitted']\n",
    "\n",
    "            # Pivot the data to create a wide format using the Question Title\n",
    "            pivot_table = survey_data.pivot_table(\n",
    "                index=['Survey Data Participant ID'],\n",
    "                columns='Survey Data Question Title',\n",
    "                values='Survey Data Answer Value',\n",
    "                aggfunc=lambda x: ' | '.join(x.dropna().astype(str))  # Separate multiple entries with a different separator\n",
    "            )\n",
    "\n",
    "            # Debugging: Check pivot table structure\n",
    "            print(\"Pivot Table Columns:\")\n",
    "            print(pivot_table.columns)\n",
    "            print(pivot_table.head())\n",
    "\n",
    "            # Reset index to merge\n",
    "            pivot_table.reset_index(inplace=True)\n",
    "\n",
    "            # Rename pivot table index for consistency\n",
    "            pivot_table.rename(columns={'Survey Data Participant ID': 'Subject'}, inplace=True)\n",
    "\n",
    "            # Merge the pivot table with the subject data\n",
    "            merged_data = pd.merge(subject_data, pivot_table, on='Subject', how='left')\n",
    "\n",
    "            # Debugging: Verify merged data\n",
    "            print(\"Merged Data:\")\n",
    "            print(merged_data.head())\n",
    "\n",
    "            # Get the last column name (conditions) to process it\n",
    "            condition_col = merged_data.columns[-1]\n",
    "\n",
    "            # Separate conditions into different columns, including \"Other\" responses\n",
    "            processed_data = separate_conditions(merged_data, condition_col)\n",
    "\n",
    "            # Write the processed data to a sheet named after the survey title\n",
    "            processed_data.to_excel(writer, sheet_name=title[:31], index=False)  # Excel sheet names are limited to 31 characters\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing '{title}': {str(e)}\")\n",
    "\n",
    "print(f\"Processed conditions data saved to: {conditions_output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
